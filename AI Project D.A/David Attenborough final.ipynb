{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "074e8541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëÄ David is watching...\n",
      "üéôÔ∏è David says:\n",
      "Behold the modern Homo sapiens in their natural habitat; a calm, indoor burrow characterized by soft textiles and a floral motif adorning the wall. This one appears engaged in a task requiring deep concentration, reflective in the eyes behind the transparent, circular shields aiding the vision. A curious ritual of data absorption through wired appendages connected to the ears is observed, an adaptation in this digital age. Magnificent!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'export'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 112\u001b[0m\n\u001b[0;32m    108\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 103\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müéôÔ∏è David says:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(analysis)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mplay_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43manalysis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m script \u001b[38;5;241m=\u001b[39m script \u001b[38;5;241m+\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: analysis}]\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# wait for 5 seconds\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 45\u001b[0m, in \u001b[0;36mplay_audio\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     41\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(audio)\n\u001b[1;32m---> 45\u001b[0m \u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\playback.py:71\u001b[0m, in \u001b[0;36mplay\u001b[1;34m(audio_segment)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[43m_play_with_ffplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_segment\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\playback.py:15\u001b[0m, in \u001b[0;36m_play_with_ffplay\u001b[1;34m(seg)\u001b[0m\n\u001b[0;32m     13\u001b[0m PLAYER \u001b[38;5;241m=\u001b[39m get_player_name()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m NamedTemporaryFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mseg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m(f\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mcall([PLAYER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-nodisp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-autoexit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-hide_banner\u001b[39m\u001b[38;5;124m\"\u001b[39m, f\u001b[38;5;241m.\u001b[39mname])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'export'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import errno\n",
    "\n",
    "from elevenlabs import generate, play, set_api_key, voices\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API\"))\n",
    "set_api_key(os.environ.get(\"ELEVENLABS_API\"))\n",
    "\n",
    "def encode_image(image_path):\n",
    "    while True:\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        except IOError as e:\n",
    "            if e.errno != errno.EACCES:\n",
    "                # Not a \"file in use\" error, re-raise\n",
    "                raise\n",
    "            # File is being written to, wait a bit and retry\n",
    "            time.sleep(0.1)\n",
    "\n",
    "\n",
    "def play_audio(text):\n",
    "    audio = generate(text, voice=voice=os.environ.get(\"ELEVENLABS_VOICE\"))\n",
    "\n",
    "    unique_id = base64.urlsafe_b64encode(os.urandom(30)).decode(\"utf-8\").rstrip(\"=\")\n",
    "    dir_path = os.path.join(\"narration\", unique_id)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(dir_path, \"audio.wav\")\n",
    "\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(audio)\n",
    "    \n",
    "\n",
    "    \n",
    "    play(audio)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def generate_new_line(base64_image):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Describe this image\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "def analyze_image(base64_image, script):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                You are Sir David Attenborough. Narrate the picture of the human as if it is a nature documentary.\n",
    "                Make it flattering and funny. Don't repeat yourself. Make it short. If I do anything remotely interesting, make a big deal about it!\n",
    "                \"\"\",\n",
    "            },\n",
    "        ]\n",
    "        + script\n",
    "        + generate_new_line(base64_image),\n",
    "        max_tokens=4096,\n",
    "    )\n",
    "    response_text = response.choices[0].message.content\n",
    "    return response_text\n",
    "\n",
    "\n",
    "def main():\n",
    "    script = []\n",
    "\n",
    "    while True:\n",
    "        # path to your image\n",
    "        image_path = os.path.join(os.getcwd(), \"C:\\\\Users\\\\sahab\\\\Untitled Folder 2\\\\frames\\\\frame.jpg\")\n",
    "\n",
    "        # getting the base64 encoding\n",
    "        base64_image = encode_image(image_path)\n",
    "\n",
    "        # analyze posture\n",
    "        print(\"üëÄ David is watching...\")\n",
    "        analysis = analyze_image(base64_image, script=script)\n",
    "\n",
    "        print(\"üéôÔ∏è David says:\")\n",
    "        print(analysis)\n",
    "\n",
    "       \n",
    "        play_audio(analysis)\n",
    "        \n",
    "        script = script + [{\"role\": \"assistant\", \"content\": analysis}]\n",
    "\n",
    "        # wait for 5 seconds\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6f831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d9e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d88ac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
